{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoDistanceEstimationTracking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPX9A0WKIpRdKPATONXYji",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PJ-cs/DistanceEstimationTracking/blob/main/DemoDistanceEstimationTracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y20w3Wc6uj-r",
        "outputId": "1c6972b1-66a0-4eee-e20f-75aa3a9ecb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DistanceEstimationTracking'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 16 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n",
            "Cloning into 'DPT'...\n",
            "remote: Enumerating objects: 776, done.\u001b[K\n",
            "remote: Counting objects: 100% (776/776), done.\u001b[K\n",
            "remote: Compressing objects: 100% (395/395), done.\u001b[K\n",
            "remote: Total 776 (delta 368), reused 720 (delta 330), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (776/776), 455.51 KiB | 1.96 MiB/s, done.\n",
            "Resolving deltas: 100% (368/368), done.\n",
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n",
            "--2022-04-08 10:40:47--  https://github.com/intel-isl/DPT/releases/download/1_0/dpt_hybrid-midas-501f0c75.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/isl-org/DPT/releases/download/1_0/dpt_hybrid-midas-501f0c75.pt [following]\n",
            "--2022-04-08 10:40:47--  https://github.com/isl-org/DPT/releases/download/1_0/dpt_hybrid-midas-501f0c75.pt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/350409920/40b50780-8b37-11eb-9027-6ef5790cdeef?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220408%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220408T104047Z&X-Amz-Expires=300&X-Amz-Signature=566c4fe3bc58322a220d3ab7daf1c618f5eeab455c31f8b590b97770dfa9263a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=350409920&response-content-disposition=attachment%3B%20filename%3Ddpt_hybrid-midas-501f0c75.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-08 10:40:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/350409920/40b50780-8b37-11eb-9027-6ef5790cdeef?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220408%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220408T104047Z&X-Amz-Expires=300&X-Amz-Signature=566c4fe3bc58322a220d3ab7daf1c618f5eeab455c31f8b590b97770dfa9263a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=350409920&response-content-disposition=attachment%3B%20filename%3Ddpt_hybrid-midas-501f0c75.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 492757791 (470M) [application/octet-stream]\n",
            "Saving to: ‘dpt_hybrid-midas-501f0c75.pt’\n",
            "\n",
            "              dpt_h  48%[========>           ] 229.23M  10.3MB/s    eta 10s    ^C\n",
            "--2022-04-08 10:40:57--  https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/isl-org/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt [following]\n",
            "--2022-04-08 10:40:58--  https://github.com/isl-org/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/350409920/3568d880-8b45-11eb-8c45-12766a421e43?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220408%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220408T104058Z&X-Amz-Expires=300&X-Amz-Signature=842c3b9745533ad5c460f13ddda54cb975f177e4660d2804791c940547b9bcab&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=350409920&response-content-disposition=attachment%3B%20filename%3Ddpt_large-midas-2f21e586.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-08 10:40:58--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/350409920/3568d880-8b45-11eb-8c45-12766a421e43?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220408%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220408T104058Z&X-Amz-Expires=300&X-Amz-Signature=842c3b9745533ad5c460f13ddda54cb975f177e4660d2804791c940547b9bcab&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=350409920&response-content-disposition=attachment%3B%20filename%3Ddpt_large-midas-2f21e586.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1376378527 (1.3G) [application/octet-stream]\n",
            "Saving to: ‘dpt_large-midas-2f21e586.pt’\n",
            "\n",
            "dpt_large-midas-2f2 100%[===================>]   1.28G  27.2MB/s    in 62s     \n",
            "\n",
            "2022-04-08 10:42:00 (21.1 MB/s) - ‘dpt_large-midas-2f21e586.pt’ saved [1376378527/1376378527]\n",
            "\n",
            "Cloning into 'AdelaiDepth'...\n",
            "remote: Enumerating objects: 270, done.\u001b[K\n",
            "remote: Counting objects: 100% (270/270), done.\u001b[K\n",
            "remote: Compressing objects: 100% (226/226), done.\u001b[K\n",
            "remote: Total 270 (delta 95), reused 150 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (270/270), 44.52 MiB | 28.30 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'pytorch'\u001b[0m\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r AdelaiDepth/LeReS/requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r AdelaiDepth/LeReS/requirements.txt (line 2)) (4.1.2.30)\n",
            "Collecting plyfile\n",
            "  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r AdelaiDepth/LeReS/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r AdelaiDepth/LeReS/requirements.txt (line 1)) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r AdelaiDepth/LeReS/requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r AdelaiDepth/LeReS/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r AdelaiDepth/LeReS/requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->-r AdelaiDepth/LeReS/requirements.txt (line 1)) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r AdelaiDepth/LeReS/requirements.txt (line 1)) (1.15.0)\n",
            "Installing collected packages: plyfile\n",
            "Successfully installed plyfile-0.7.4\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libsparsehash-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 72.4 kB of archives.\n",
            "After this operation, 612 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsparsehash-dev all 2.0.2-1 [72.4 kB]\n",
            "Fetched 72.4 kB in 1s (94.1 kB/s)\n",
            "Selecting previously unselected package libsparsehash-dev.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../libsparsehash-dev_2.0.2-1_all.deb ...\n",
            "Unpacking libsparsehash-dev (2.0.2-1) ...\n",
            "Setting up libsparsehash-dev (2.0.2-1) ...\n",
            "Collecting git+https://github.com/mit-han-lab/torchsparse.git\n",
            "  Cloning https://github.com/mit-han-lab/torchsparse.git to /tmp/pip-req-build-knid1sah\n",
            "  Running command git clone -q https://github.com/mit-han-lab/torchsparse.git /tmp/pip-req-build-knid1sah\n",
            "Building wheels for collected packages: torchsparse\n",
            "  Building wheel for torchsparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchsparse: filename=torchsparse-1.4.0-cp37-cp37m-linux_x86_64.whl size=7945661 sha256=490b0b88144c6ed8334b2cbc6c41c52ba4a8d4091bfc932f97cf287e9654e686\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cnas8edu/wheels/af/d6/f4/5df3e8cd686a70d63b69519c2a8d320931e3d1dd480308b20f\n",
            "Successfully built torchsparse\n",
            "Installing collected packages: torchsparse\n",
            "Successfully installed torchsparse-1.4.0\n",
            "Cloning into 'dino'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Total 168 (delta 0), reused 0 (delta 0), pack-reused 168\u001b[K\n",
            "Receiving objects: 100% (168/168), 24.44 MiB | 22.38 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n",
            "--2022-04-08 10:45:09--  https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 86728949 (83M) [application/zip]\n",
            "Saving to: ‘dino_deitsmall8_pretrain.pth’\n",
            "\n",
            "dino_deitsmall8_pre 100%[===================>]  82.71M  79.9MB/s    in 1.0s    \n",
            "\n",
            "2022-04-08 10:45:11 (79.9 MB/s) - ‘dino_deitsmall8_pretrain.pth’ saved [86728949/86728949]\n",
            "\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from filterpy) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from filterpy) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from filterpy) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->filterpy) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->filterpy) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->filterpy) (1.15.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110474 sha256=db0a263c3bf883d7e5a09f51db70183c47977827477f65bcfa0382f882547620\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/e0/ee/a2b3c5caab3418c1ccd8c4de573d4cbe13315d7e8b0a55fbc2\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n",
            "Collecting lap\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 8.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: lap\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1590208 sha256=f13637ced59d85033fde47690b80892ee4a9f0d889c7027280bfcf46660af61c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/0b/e3/ef9daf1b5547b56389e42c80c3100f1e6479bf5fd00fd9d6ba\n",
            "Successfully built lap\n",
            "Installing collected packages: lap\n",
            "Successfully installed lap-0.4.0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "install requirements:\n",
        "repos: Main Repo, DINO, DPT (with additional weights)\n",
        "\"\"\"\n",
        "!git clone https://github.com/PJ-cs/DistanceEstimationTracking.git\n",
        "\n",
        "\n",
        "!git clone https://github.com/intel-isl/DPT.git\n",
        "!pip install timm\n",
        "!wget https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\n",
        "!mv dpt_hybrid-midas-501f0c75.pt DPT/weights\n",
        "!mv dpt_large-midas-2f21e586.pt DPT/weights\n",
        "\n",
        "!git clone https://github.com/aim-uofa/AdelaiDepth.git\n",
        "!pip install pytorch==1.6.0 torchvision=0.7.0 cudatoolkit=10.2 -c pytorch\n",
        "!pip install -r AdelaiDepth/LeReS/requirements.txt\n",
        "!apt-get install libsparsehash-dev\n",
        "!pip install --upgrade  git+https://github.com/mit-han-lab/torchsparse.git@e268836e64513b9a31c091cd1d517778d4c1b9e6\n",
        "    \n",
        "    \n",
        "!git clone https://github.com/facebookresearch/dino.git\n",
        "!wget https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain.pth\n",
        "!mv dino_deitsmall8_pretrain.pth dino\n",
        "\n",
        "!pip install filterpy\n",
        "!pip install lap\n",
        "\n",
        "!mv DistanceEstimationTracking/dataset.py .\n",
        "!mv DistanceEstimationTracking/models.py .\n",
        "!mv DistanceEstimationTracking/sort_2_5D.py ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import argparse\n",
        "\n",
        "import cv2\n",
        "import os \n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageFile, ImageFont, ImageDraw\n",
        "import shutil\n",
        "from sort_2_5D import Sort2_5D, KalmanBoxTracker\n",
        "import glob\n",
        "from models import SPVCNN_CLASSIFICATION\n",
        "import torch\n",
        "from dataset import *\n",
        "from torchsparse.utils.helpers import sparse_collate_tensors\n",
        "from collections import OrderedDict\n",
        "import glob\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"DPT\")\n",
        "import DPT.run_monodepth as run_dpt_depth\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\"HYPERPARAMETERS\"\"\"\n",
        "ALPHA_IOU = 0.4270 # ! >0 [0, 1]\n",
        "#BETA_DISTZ = 0.5 # ! >0   = 1 - alpha_iou\n",
        "MAX_DIST = 4.0962 # [m]\n",
        "IOU_THRES = 0.0101\n",
        "MAX_AGE = 111\n",
        "MIN_HITS = 1\n",
        "DET_CONF_THRES = 0.9160973480326474 # 0.9\n",
        "\n",
        "PERCENTILE = 50\n",
        "DINO_THRESH = 26 # [0, 255]\n",
        "DINO_RES = 256 # or 512\n",
        "\n",
        "def dino_semseg(rgb_dir, output_dir, threshold = DINO_THRESH):\n",
        "    # output_dir must be empty, mask-original_file_name in output dir\n",
        "    #os.system(f'python dino/video_generation.py --pretrained_weights dino_deitsmall8_pretrain.pth --input_path \"{rgb_dir}\" --output_path \"{output_dir}\" --resize 512 ')\n",
        "    stream = os.popen(f'python dino/video_generation.py --pretrained_weights \"dino/dino_deitsmall8_pretrain.pth\" --input_path \"{rgb_dir}\" --output_path \"{output_dir}\" --resize {DINO_RES} ') #TODO reconsider resize\n",
        "    output = stream.readlines()\n",
        "    stream.close()\n",
        "    attn_dir = os.path.join(output_dir, \"attention\")\n",
        "    for line in output:\n",
        "        print(line)\n",
        "    # delete unnecessary video\n",
        "    #os.remove(os.path.join(output_dir, \"video.mp4\"))\n",
        "    # create binary masks of images, names: mask-original_file_name and resize to original res\n",
        "    for rgb_img in os.scandir(rgb_dir):\n",
        "        if rgb_img.is_file() and (rgb_img.name.endswith(\".jpg\") or rgb_img.name.endswith(\".png\")):\n",
        "            # open att_img and get original shape\n",
        "            rgb_shape = cv2.imread(rgb_img.path).shape[:2]\n",
        "            att_img_path = os.path.join(attn_dir, \"attn-\"+rgb_img.name)\n",
        "            att_img_file = cv2.imread(att_img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            # resize att img to orignal dims\n",
        "            att_img_res = cv2.resize(att_img_file, (rgb_shape[1], rgb_shape[0]))\n",
        "            # create binary mask\n",
        "            att_img_res[att_img_res <= threshold] = 0\n",
        "            att_img_res[att_img_res > threshold] = 255\n",
        "            # save mask\n",
        "            cv2.imwrite(os.path.join(output_dir, \"mask-\"+rgb_img.name[:-3]+\"png\"), att_img_res)\n",
        "            \n",
        "    # delete attention dir\n",
        "    shutil.rmtree(attn_dir) \n",
        "\n",
        "\"\"\"inference notebook\"\"\"\n",
        "\n",
        "\n",
        "# TODO add later: argparse for these arguments and change focal_length calculation\n",
        "input_frames_dir = \"datasets/lindenthal/images/20200807015315/color\"\n",
        "input_focal_lenght_px = 424.7448425292969\n",
        "algn_out_dir = \"inference_test/algn_out\"\n",
        "tracks_out_dir = \"inference_test\"\n",
        "\n",
        "mega_det_onnx_path = \"DeepChimpact/weights/md_v4.1.0.onnx\"\n",
        "pvcnn_weights_path = \"inference_test/epoch_6.pth\"\n",
        "dpt_weights_path = \"DPT/weights/dpt_large-midas-2f21e586.pt\"\n",
        "\n",
        "# end argparse\n",
        "\n",
        "crops_temp_folder = \"temp/crops\"\n",
        "masks_temp_folder = \"temp/masks\"\n",
        "dpt_temp_folder = \"temp/dpt\"\n",
        "# detections_temp_folder = \"temp/detections\"\n",
        "tracks_out_path = os.path.join(tracks_out_dir, os.path.basename(input_frames_dir)+\".csv\")\n",
        "img_height = 0\n",
        "img_width = 0\n",
        "\n",
        "os.makedirs(crops_temp_folder, exist_ok=True)\n",
        "os.makedirs(masks_temp_folder, exist_ok=True)\n",
        "os.makedirs(dpt_temp_folder, exist_ok=True)\n",
        "\n",
        "# get img_height, img_width\n",
        "for rgb_img in os.scandir(input_frames_dir):\n",
        "    if rgb_img.is_file() and rgb_img.name.endswith((\".png\", \".jpg\")):\n",
        "        test_img = cv2.imread(rgb_img.path)\n",
        "        img_height, img_width = test_img.shape[:2]\n",
        "        break\n",
        "\n",
        "\n",
        "# print(f\"1: Calculating DPT images, saving to {dpt_temp_folder} ...\")\n",
        "# run_dpt_depth.run(input_frames_dir,\n",
        "#                   dpt_temp_folder,\n",
        "#                   dpt_weights_path,\n",
        "#                   \"dpt_large\")\n",
        "\n",
        "print(f\"2: Converting Relative Depth images to absolute images via PVCNN, saving results to {algn_out_dir}...\")\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "voxel_size=0.01\n",
        "num_points=50000\n",
        "spvcnn_model = SPVCNN_CLASSIFICATION(input_channel=3, num_classes=2, cr=1.0, pres=voxel_size, vres=voxel_size)\n",
        "checkpoint = torch.load(pvcnn_weights_path, map_location=device)\n",
        "spvcnn_model.load_state_dict(checkpoint['spvcnn_model_state_dict'])\n",
        "\n",
        "# move model to device\n",
        "spvcnn_model.to(device)\n",
        "spvcnn_model.eval()\n",
        "\n",
        "# transforms, datasets, dataloader\n",
        "dpt_transforms = get_transforms_dpt(voxel_size, num_points)\n",
        "\n",
        "img_paths = glob.glob(os.path.join(dpt_temp_folder, \"*.pfm\"))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for dpt_img_file in tqdm(img_paths):\n",
        "\n",
        "        dpt_img = cv2.imread(dpt_img_file, cv2.IMREAD_UNCHANGED)\n",
        "        dpt_img_name = os.path.basename(dpt_img_file)\n",
        "        # transform dpt desparity to relative depth\n",
        "        dpt_pcd = dpt_img.copy()\n",
        "\n",
        "\n",
        "        dpt_pcd -= dpt_pcd.min()\n",
        "        dpt_pcd /= dpt_pcd.max()\n",
        "        dpt_pcd = 1./(dpt_pcd*0.5+0.02)\n",
        "        dpt_pcd_tensor = torch.from_numpy(dpt_pcd).unsqueeze(0)\n",
        "        \n",
        "        dpt_shape = tuple(dpt_pcd_tensor.shape[-2:])\n",
        "        gt_shape = (img_height, img_width)\n",
        "        \n",
        "        if dpt_shape != gt_shape:\n",
        "          dpt_pcd_tensor =torch.nn.functional.interpolate(\n",
        "                          dpt_pcd_tensor.unsqueeze(0),\n",
        "                          size=gt_shape,\n",
        "                          mode=\"bicubic\",\n",
        "                          align_corners=False,).squeeze(0)\n",
        "            \n",
        "        # transform dpt img to pointcloud\n",
        "        dpt_sparse, dpt_normalized = dpt_transforms((dpt_pcd_tensor, input_focal_lenght_px))\n",
        "        dpt_sparse_input = sparse_collate_tensors([dpt_sparse]).to(device)\n",
        "\n",
        "        # inference\n",
        "        model_out = spvcnn_model(dpt_sparse_input)\n",
        "        scale_out = model_out[:,0]\n",
        "        shift_out = model_out[:,1]\n",
        "\n",
        "        # align depth image with output\n",
        "        dpt_aligned = dpt_pcd_tensor.squeeze(0).squeeze(0).cpu().numpy() * scale_out[0].cpu().numpy() + shift_out[0].cpu().numpy()\n",
        "\n",
        "        # save output\n",
        "        cv2.imwrite(os.path.join(algn_out_dir, dpt_img_name), dpt_aligned)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"3: Calculating Detections, saving crops to {crops_temp_folder}...\")\n",
        "mega_det_net = cv2.dnn.readNetFromONNX(mega_det_onnx_path) \n",
        "rgb_img_paths = [rgb_img.path for rgb_img in os.scandir(input_frames_dir) if rgb_img.is_file() and rgb_img.name.endswith((\".png\", \".jpg\"))]\n",
        "frame_det_dict = []\n",
        "\n",
        "# TODO skip first 30 frames\n",
        "for rgb_img_path in tqdm(rgb_img_paths):\n",
        "    frame_name = os.path.basename(rgb_img_path)\n",
        "    input_pil = Image.open(rgb_img_path)\n",
        "    input_cv = cv2.imread(rgb_img_path)\n",
        "    frame_height = input_pil.height\n",
        "    frame_width = input_pil.width\n",
        "    \n",
        "    frame_det_dict[frame_name] = {}\n",
        "    \n",
        "    # TODO insert preprocessing and saving code here\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    #\n",
        "    \n",
        "    \n",
        "    for det_ind, detection in enumerate(detections):\n",
        "        if detection[\"category\"] != \"1\" or detection[\"conf\"] < DET_CONF_THRES:\n",
        "            continue\n",
        "        # TODO bb = detection ?\n",
        "        bbx = int(bb[0] * frame_width)\n",
        "        bby = int(bb[1] * frame_height)\n",
        "        bbwidth = int(bb[2] * frame_width)\n",
        "        bbheight = int(bb[3] * frame_height)\n",
        "        # print(bbx, bby, bbwidth, bbheight\n",
        "\n",
        "        # new bb\n",
        "        # egde cases, want to guarantee new bb with double the old size\n",
        "        bbx_buffer = bbx - (bbwidth // 2) if bbx - (bbwidth // 2) >= 0 else 0\n",
        "        bbwidth_buffer = 2 * bbwidth \n",
        "        if bbx_buffer + bbwidth_buffer >= frame_width: # move bbx to the left by amount of difference over allowed width\n",
        "\n",
        "            bbx_buffer = frame_width- bbwidth_buffer \n",
        "\n",
        "            if bbx_buffer < 0:\n",
        "                bbx_buffer = 0\n",
        "                bb_width_buffer = frame_width\n",
        "\n",
        "        bby_buffer = bby - (bbheight // 2) if bby - (bbheight // 2) >= 0 else 0\n",
        "        bbheight_buffer = 2 * bbheight \n",
        "        if bby_buffer + bbheight_buffer >= frame_height:\n",
        "            bby_buffer = frame_height - bbheight_buffer \n",
        "            if bby_buffer < 0:\n",
        "                bby_buffer = 0\n",
        "                bb_height_buffer = frame_height\n",
        "\n",
        "        img_det_part = np.copy(input_cv[bby_buffer: bby_buffer + bbheight_buffer, bbx_buffer: bbx_buffer + bbwidth_buffer])\n",
        "\n",
        "\n",
        "        # save to crop_folder\n",
        "\n",
        "        #print(os.path.join(crop_folder, frame_name[:-4]+f\"_{det_ind:04d}.png\"))\n",
        "\n",
        "        bbx_crop = bbx - bbx_buffer\n",
        "        bby_crop = bby - bby_buffer\n",
        "        # reuse bbwidht, bbheight when extracting depth\n",
        "        frame_det_dict[frame_name][det_ind] = [(bbx, bby, bbwidth, bbheight), (bbx_crop, bby_crop)]\n",
        "\n",
        "        assert np.all(img_det_part[bby_crop: bby_crop + bbheight, bbx_crop: bbx_crop + bbwidth] == frame_img[bby: bby + bbheight, bbx: bbx + bbwidth])\n",
        "        img_det_part -= img_det_part.min()\n",
        "        img_det_part *= int(255/img_det_part.max())\n",
        "\n",
        "        cv2.imwrite(os.path.join(crops_temp_folder, frame_name[:-4]+f\"_{det_ind:04d}.png\"), img_det_part)\n",
        "\n",
        "\n",
        "print(f\"4: Starting dino segmentation, saving masks to {masks_temp_folder}...\")\n",
        "semseg_f(crops_temp_folder, masks_temp_folder)\n",
        "\n",
        "print(f\"5: Extracting distances of detections to camera...\")\n",
        "for frame_name, dets_dict in tqdm(frame_det_dict.items()):\n",
        "    depth_img = cv2.imread(os.path.join(algn_out_dir, frame_name[:-3]+\"pfm\"), cv2.IMREAD_UNCHANGED)\n",
        "    frame_height, frame_width = depth_img.shape[:2]\n",
        "    \n",
        "    for det_ind, det_info in (dets_dict.values()):\n",
        "        bbx, bby, bbwidth, bbheight = det_info[0]\n",
        "        bbx_crop, bby_crop = det_info[1]\n",
        "        \n",
        "        # open segmentation mask for detection\n",
        "        seg_det_full = cv2.imread(os.path.join(masks_temp_folder, \"mask-\"+frame_name[:-4]+f\"_{det_ind:04d}.png\"), cv2.IMREAD_GRAYSCALE) / 255\n",
        "        seg_det_crop = seg_det_full[bby_crop: bby_crop + bbheight, bbx_crop: bbx_crop + bbwidth]\n",
        "        \n",
        "        # get detection crop of depth img\n",
        "        depth_det_crop = depth_img[bby: bby + bbheight, bbx: bbx + bbwidth]\n",
        "        \n",
        "        depth_values_seg = depth_det_crop[np.where((seg_det_crop == 1))[:2]]\n",
        "        if (seg_det_crop == 1).any() == False:\n",
        "            print(frame_name, f\"no sem seg pixel of deer in bb {bby},{bbx} dist = {PERCENTILE}th percentile\")\n",
        "            det_info.append(float(np.percentile(depth_det_crop, PERCENTILE)))\n",
        "        else:\n",
        "            det_info.append(float(np.percentile(depth_values_seg, PERCENTILE)))\n",
        "            \n",
        "print(f\"6: Connecting positions of animals over video to coherent tracks...\")\n",
        "KalmanBoxTracker.count = 0\n",
        "# init Sort\n",
        "mot_tracker = Sort2_5D(max_age=MAX_AGE, min_hits=MIN_HITS, iou_threshold=IOU_THRES, alpha_iou=ALPHA_IOU, max_dist=MAX_DIST)\n",
        "\n",
        "frame_det_dict = OrderedDict(sorted(frame_det_dict.items(), key=lambda x: abs(int(x[0][:-4]))))\n",
        "\n",
        "cam_u0 = img_width / 2.0 #848 / 2.0 #frame_depth.shape[1] / 2.0\n",
        "cam_v0 = img_height / 2.0 # 480 / 2.0\n",
        "\n",
        "with open(tracks_out_path, 'w', newline='') as csvfile:\n",
        "    fieldnames = ['frame_name', 'track_num', 'bb_x', 'bb_y', 'bb_width', 'bb_height', '3D_x', '3D_y', '3D_z']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    \n",
        "    for frame_name, dets_dict in tqdm(frame_det_dict.items()):\n",
        "        frame_bbxs = []\n",
        "\n",
        "        for det_ind, det_info in (dets_dict.values()):\n",
        "            bbx, bby, bbwidth, bbheight = det_info[0]\n",
        "            distance = det_info[2]\n",
        "            frame_bbxs.append(np.array([bbx, bby, bbx+bbwidth, bby+bbheight, distance]))\n",
        "        if len(frame_bbxs) == 0: # no detections in frame\n",
        "            frame_bbxs = np.empty((0, 5))\n",
        "\n",
        "        trackers = mot_tracker.update(frame_bbxs)\n",
        "\n",
        "        for d in trackers:\n",
        "            x1,y1,w, h,distance, track_num = d\n",
        "\n",
        "            # calculations to project position of animal to 3d\n",
        "            # middle of lower bound of bounding box\n",
        "            x3d = x1 + 0.5 * w\n",
        "            y3d = y1 + h\n",
        "\n",
        "            # project to 3d\n",
        "            x3d = x3d / input_focal_lenght_px * distance\n",
        "            y3d = y3d / input_focal_lenght_px * distance\n",
        "\n",
        "            writer.writerow({'frame_name': frame_name, 'track_num': track_num, 'bb_x':x1, 'bb_y':y1, 'bb_width':w, 'bb_height':h, '3D_x':x3d, '3D_y':y3d, '3D_z':distance})\n",
        "            \n",
        "# TODO create 3d plot of everything...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "W6jKKyy4xOsg",
        "outputId": "05c464ff-380b-49a5-9272-e343d4acb3d9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-673914df4c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# get img_height, img_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrgb_img\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_frames_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgb_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrgb_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/lindenthal/images/20200807015315/color'"
          ]
        }
      ]
    }
  ]
}